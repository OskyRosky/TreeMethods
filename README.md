# Tree Methods

 4 Classes of tree methods

------------------------------------------------------------------------------------------

**Repository summary**

1.  **Intro** ğŸ§³

2.  **Tech Stack** ğŸ¤–

3.  **Features** ğŸ¤³ğŸ½

4.  **Process** ğŸ‘£

5.  **Learning** ğŸ’¡

6.  **Improvement** ğŸ”©

7.  **Running the Project** âš™ï¸

8.  **More** ğŸ™ŒğŸ½



In addition to the core content, this repository offers:

Python code examples for a hands-on learning experience.
Community contributions showcasing diverse approaches to NLP problems.
A section for FAQs to help troubleshoot common issues encountered during ML project development.

------------------------------------------------------------------------------------------


# 1. Decision Trees

## Intro 

## CART (Classification and Regression Trees)

## ID3 (Iterative Dichotomiser 3)

## C4.5

## CHAID (Chi-squared Automatic Interaction Detection)

## MARS (Multivariate Adaptive Regression Splines)

## QUEST (Quick, Unbiased, Efficient Statistical Tree):

# 2. Random Forests

## Intro

## Standard Random Forest

## ExtraTrees (Extremely Randomized Trees)

# 3. Boosting Methods

## Intro

## AdaBoost (Adaptive Boosting)

## Gradient Boosting Machine (GBM)

## XGBoost (Extreme Gradient Boosting)

## LightGBM (Light Gradient Boosting Machine)

## CatBoost (Categorical Boosting)

## Histogram-Based Gradient Boosting (HGB)



# 4. Combined Methods and Variants

## Intro

## Stochastic Gradient Boosting

## Bagging (Bootstrap Aggregating)

## Isolation Forest

## Oblique Decision Trees

## Rotation Forest
